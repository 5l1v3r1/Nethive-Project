input {
    beats {
        port => 5044
    }
}

## Add your filters / logstash plugins configuration here
filter {
    if [log_type] == "TYPE_AUDIT" {

    }
    else if [log_type] == "TYPE_PARSED_SLOG" {
        json {
            source => "message"
        }
    }
    else if [log_type] == "TYPE_BASH" {

    }
    else if [log_type] == "TYPE_BASH_CENTRALIZED" {
        grok {
            match => { "message" => "%{TIMESTAMP_ISO8601:log_time} : %{USER:user}@%{IPORHOST:source} : %{PATH:cwd} : %{GREEDYDATA:command}" }
        }
    }
    else if [log_type] == "TYPE_HTTP" {
        json {
            source => "message"
        }
    }
}

output {
    elasticsearch {
        hosts => "elasticsearch:9200"integrated packetbeat with docker 
        user => "elastic"
        password => "changeme"
        index => "%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}"
        document_type => "%{[@metadata][type]}"
    }
    stdout {
        codec => rubydebug
    }
    if [type] == "mysql" {
        tcp {
            codec => json_lines
            host => "172.17.0.1" # change this to docker interface ip address (host)
            port => 5128
        }
    }
}